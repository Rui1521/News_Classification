{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../datas/bbc_preprocessed.json') as f:\n",
    "    datas = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(5220)\n",
    "random.shuffle(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = [data['category'] for data in datas]\n",
    "mp = {'Technology':0,'Entertainment & Arts':1,'Business':2,'Health':3,'Science & Environment':4}\n",
    "inv_mp = {v:k for k, v in mp.items()}\n",
    "cat = [mp[x] for x in cate]\n",
    "cont = [' '.join(data['content']) for data in datas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devide into train / valid / test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(\n",
    "    cont, cat, test_size=0.3, random_state=5220)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_tv, y_tv, test_size=0.5, random_state=5220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes without tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbw_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbw_clf.fit(X_train, y_train)\n",
    "nbw_valid_predicts = nbw_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1538,   11,   55,    2,   27],\n",
       "       [  32,  960,   33,    0,    0],\n",
       "       [ 246,   24, 1931,   11,   23],\n",
       "       [   7,    0,    7,  263,    3],\n",
       "       [   8,    4,   27,   10,  365]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nbw_cm = confusion_matrix(y_valid, nbw_valid_predicts)\n",
    "nbw_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf.fit(X_train, y_train)\n",
    "nb_valid_predicts = nb_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,    0,  218,    0,    0],\n",
       "       [  46,  842,  137,    0,    0],\n",
       "       [ 142,    1, 2091,    1,    0],\n",
       "       [  44,    0,  219,   17,    0],\n",
       "       [  74,    2,  284,    0,   54]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb_cm = confusion_matrix(y_valid, nb_valid_predicts)\n",
    "nb_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', SGDClassifier(tol=1e-3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.fit(X_train, y_train)\n",
    "svm_valid_predicts = svm_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1527,   14,   76,    4,   12],\n",
       "       [   8, 1004,   13,    0,    0],\n",
       "       [ 140,   19, 2052,   10,   14],\n",
       "       [   5,    0,    4,  266,    5],\n",
       "       [  13,    3,   14,    8,  376]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_cm = confusion_matrix(y_valid, svm_valid_predicts)\n",
    "svm_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busi', 'bank', 'chief', 'compani', 'quarter', 'deal', 'economi', 'trade', 'mr', 'share', 'enabl', 'econom', 'big', 'advertis', 'sharehold', 'argu', 'manag', 'davo', 'forecast', 'competit', 'tax', 'boe', 'founder', 'rise', 'execut', 'plant', 'insur', 'person', 'transpar', 'profit', 'singapor', 'corpor', 'openreach', 'verizon', 'global', 'obr', 'fire', 'rose', 'iot', 'pension', 'sfo', 'food', 'credit', 'interact', 'debt', 'switch', 'penalti', 'student', 'jump', 'interdigit', 'banknot', 'foreign', 'ban', '1bn', 'oil', 'buy', 'farmer', 'suspend', 'ms', 'cabl', 'class', 'rent', 'buyer', 'month', 'car', 'tuesday', 'strong', 'worker', 'vw', 'regul', 'so', 'tradit', 'don', 'rb', 'fall', 'carmak', 'ski', 'hmrc', 'supermarket', 'discount', 'reader', 'work', 'earlier', 'york', 'html5', 'ashley', 'malvern', 'infring', 'board', 'monthli', 'porn', 'giant', 'custom', 'august', 'holiday', 'toy', 'save', 'edf', 'bp', 'cuba']\n",
      "[2.4331771592378799, 2.4138683809985273, 2.2274573302851985, 2.0212643524676186, 1.8635814945298266, 1.6295962954133907, 1.6192893701636362, 1.5031597402652948, 1.4734550344789281, 1.3453818720400905]\n",
      "38376\n"
     ]
    }
   ],
   "source": [
    "vocab = tfiVect.vocabulary_\n",
    "rev_vocab = {v:k for k,v in vocab.items()}\n",
    "indexes = coef[2].argsort()[::-1][:100]\n",
    "print([rev_vocab[i] for i in indexes])\n",
    "print(sorted(coef[4])[::-1][:10])\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of classes in training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories             Training Validation\n",
      "Technology                 1656       1633\n",
      "Entertainment & Arts        973       1025\n",
      "Business                   2279       2235\n",
      "Health                      285        280\n",
      "Science & Environment       394        414\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter_y_train = Counter(y_train)\n",
    "counter_y_valid = Counter(y_valid)\n",
    "\n",
    "def format1(s1, s2, s3):\n",
    "    return \"{:22} {:>8} {:>10}\".format(s1, s2, s3)\n",
    "\n",
    "print(format1(\"Categories\", \"Training\", \"Validation\"))\n",
    "for k,v in mp.items():\n",
    "    print(format1(k, counter_y_train[v], counter_y_valid[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories             Training Validation\n",
      "Technology                29.64%     29.23%\n",
      "Entertainment & Arts      17.42%     18.35%\n",
      "Business                  40.79%     40.00%\n",
      "Health                     5.10%      5.01%\n",
      "Science & Environment      7.05%      7.41%\n"
     ]
    }
   ],
   "source": [
    "def format2(s1, s2, s3):\n",
    "    return \"{:22} {:8.2f}% {:9.2f}%\".format(s1, s2, s3)\n",
    "\n",
    "print(format1(\"Categories\", \"Training\", \"Validation\"))\n",
    "for k,v in mp.items():\n",
    "    print(format2(k, 100*counter_y_train[v]/sum([v for k,v in counter_y_train.items()]), 100*counter_y_valid[v]/sum([v for k,v in counter_y_valid.items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effectiveness for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes without tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      1633\n",
      "          1       0.96      0.94      0.95      1025\n",
      "          2       0.94      0.86      0.90      2235\n",
      "          3       0.92      0.94      0.93       280\n",
      "          4       0.87      0.88      0.88       414\n",
      "\n",
      "avg / total       0.91      0.91      0.91      5587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "nbw_precisions, nbw_recalls, nbw_f1s, _ = precision_recall_fscore_support(y_valid, nbw_valid_predicts)\n",
    "print(classification_report(y_valid, nbw_valid_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.84      1633\n",
      "          1       1.00      0.82      0.90      1025\n",
      "          2       0.71      0.94      0.81      2235\n",
      "          3       0.94      0.06      0.11       280\n",
      "          4       1.00      0.13      0.23       414\n",
      "\n",
      "avg / total       0.83      0.79      0.76      5587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "nb_precisions, nb_recalls, nb_f1s, _ = precision_recall_fscore_support(y_valid, nb_valid_predicts)\n",
    "print(classification_report(y_valid, nb_valid_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92      1633\n",
      "          1       0.97      0.98      0.97      1025\n",
      "          2       0.95      0.92      0.93      2235\n",
      "          3       0.92      0.95      0.94       280\n",
      "          4       0.92      0.91      0.92       414\n",
      "\n",
      "avg / total       0.94      0.94      0.94      5587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "svm_precisions, svm_recalls, svm_f1s, _ = precision_recall_fscore_support(y_valid, svm_valid_predicts)\n",
    "print(classification_report(y_valid, svm_valid_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To be continued"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
